Learning Rate (0.001): A common starting point for Adam optimizer in transfer learning; balances convergence speed and stability.
Batch Size (64): A standard batch size for image data, providing a good balance between memory usage and gradient stability. [1]
Epochs (20): A reasonable number of training passes to allow the model to learn, while mitigating the risk of overfitting.
These values were chosen as practical initial settings, common in similar image classification tasks using transfer learning with ResNet-50.
